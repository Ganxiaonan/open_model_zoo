evaluations:
  - name: smartlab-action-recognition-encoder-0001
    module: custom_evaluators.sequential_action_recognition_evaluator.SequentialActionRecognitionEvaluator
    module_config:
      network_info:
        # need to specify model path
        topview_encoder:
          model: C:\Users\kminemur\open_model_zoo\intel\smartlab-action-recognition-encoder-0001\FP32\1280vec-mobilenet-v2.xml
        frontview_encoder:
          model: C:\Users\kminemur\open_model_zoo\intel\smartlab-action-recognition-encoder-0001\FP32\1280vec-mobilenet-v2.xml
        decoder:
          model: C:\Users\kminemur\open_model_zoo\intel\smartlab-action-recognition-decoder-0001\FP32\concat-classifier.xml
        # encoder:
        #   model: C:\Users\kminemur\open_model_zoo\intel\smartlab-action-recognition-encoder-0001\FP32\1280vec-mobilenet-v2.xml
        # decoder:
        #   model: C:\Users\kminemur\open_model_zoo\intel\smartlab-action-recognition-decoder-0001\FP32\concat-classifier.xml


      launchers:
        - framework: dlsdk

      datasets:
        - name: DSI1867
          data_source: C:\Users\kminemur\DSI-1867_small\action_recognition\streams_3\high

          annotation_conversion:
            images_dir: C:\Users\kminemur\DSI-1867_small\action_recognition\streams_3
            annotation_txt: C:\Users\kminemur\DSI-1867_small\action_recognition\labels\streams_3.txt
            converter: smartlab_action

          preprocessing:
            - type: resize
              size: 224
              aspect_ratio_scale: fit_to_window

          metrics:
            - type: clip_accuracy
              presenter: print_vector
              reference:
                clip_accuracy: -1.0 #TODO
                video_accuracy: -1.0 #TODO
                mean: -1.0 #TODO